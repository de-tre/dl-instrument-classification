{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import keras\n",
    "import pickle\n",
    "import keras.initializers\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory for source files\n",
    "ROOT = \"all_samples_wav\"\n",
    "folders = os.listdir(ROOT) # names of subfolders\n",
    "file_data = [] # filenames in each of the 58 folders\n",
    "TARGET_SECONDS = 3\n",
    "\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "n_mfcc = 13\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 635.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for label in tqdm(range(len(folders))):\n",
    "    sub_dir = os.listdir(f'{ROOT}/{folders[label]}')\n",
    "    file_data.append(sub_dir)\n",
    "    \n",
    "    # Because there are multiple subfolders inside 'percussion', count the data inside too\n",
    "    # if folders[label]=='percussion':\n",
    "    #     sub_dir = os.listdir(f'{ROOT}/percussion')\n",
    "    #     for i in range(len(sub_dir)):\n",
    "    #         contents = os.listdir(f'{ROOT}/percussion/{sub_dir[i]}')\n",
    "    #         file_data.append(contents)\n",
    "            \n",
    "    # else:\n",
    "    #     file_data.append(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders: 19\n",
      "Total amount of samples: 13533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>banjo</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bassoon</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bass_clarinet</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cello</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clarinet</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>contrabassoon</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cor_anglais</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>double_bass</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flute</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>french_horn</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>guitar</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mandolin</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oboe</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>saxophone</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>trombone</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trumpet</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tuba</td>\n",
       "      <td>972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>viola</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>violin</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           folder  amount\n",
       "0           banjo      74\n",
       "1         bassoon     720\n",
       "2   bass_clarinet     944\n",
       "3           cello     889\n",
       "4        clarinet     846\n",
       "5   contrabassoon     710\n",
       "6     cor_anglais     691\n",
       "7     double_bass     852\n",
       "8           flute     878\n",
       "9     french_horn     652\n",
       "10         guitar     106\n",
       "11       mandolin      80\n",
       "12           oboe     596\n",
       "13      saxophone     732\n",
       "14       trombone     831\n",
       "15        trumpet     485\n",
       "16           tuba     972\n",
       "17          viola     973\n",
       "18         violin    1502"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Include percussion subfolders into labels\n",
    "# \n",
    "# removed = folders.pop(13)\n",
    "# # folders.insert(13, os.listdir(f'{ROOT}/percussion'))\n",
    "# perc_sub_dir = os.listdir(f'{ROOT}/percussion')\n",
    "# for i in range(len(perc_sub_dir)):\n",
    "#     folders.insert(13+i, perc_sub_dir[i])\n",
    "# \n",
    "print(f'Number of folders: {len(file_data)}')\n",
    "\n",
    "# Folders 13 - 51 are subfolders in the 'Percussion' directory with distinct \n",
    "# They will be trained individually, but summed up as percussion in the end\n",
    "# file_data[13:51]\n",
    "\n",
    "amounts = []\n",
    "for i in range(len(file_data)):\n",
    "    amounts.append(len(file_data[i]))\n",
    "\n",
    "col1 = np.array(folders)\n",
    "col2 = np.array(amounts)\n",
    "merge = {'folder': col1, 'amount': col2}\n",
    "\n",
    "df = pd.DataFrame(merge, columns=['folder', 'amount'])\n",
    "                   \n",
    "print(f'Total amount of samples: {sum(amounts)}')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load audio data; only up to 3 seconds. Shorter soundfiles are being zero-padded to reach 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(ROOT):\n",
    "    for filename in filenames:\n",
    "        src = f'{dirname}/{filename}'\n",
    "        audio_data.append(lr.load(src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Load audio_waves array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('audio_data.pickle', 'wb') as f:\n",
    "    pickle.dump(audio_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "# with open('audio_data.pickle', 'rb') as f:\n",
    "#     audio_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = []\n",
    "classID = []\n",
    "num_samples = []\n",
    "\n",
    "df1 = pd.DataFrame(np.array(audio_data, dtype=object), columns=['signal', 'samplerate'])\n",
    "\n",
    "for i in range(df1.shape[0]):\n",
    "    num_samples.append(len(df1['signal'].iloc[i]))\n",
    "num_samples = np.array(num_samples)\n",
    "\n",
    "for dirname, _, filenames in os.walk(ROOT):\n",
    "    for filename in filenames:\n",
    "        fname.append(filename)\n",
    "        classID.append(dirname[16:])\n",
    "fname = np.array(fname)\n",
    "classID = np.array(classID)\n",
    "\n",
    "df1['num samples'] = num_samples\n",
    "df1['seconds'] = df1['num samples']/df1['samplerate']\n",
    "df1['fname'] = fname\n",
    "df1['classID'] = classID\n",
    "\n",
    "# round seconds\n",
    "df1['seconds'] = df1['seconds'].apply(pd.to_numeric, errors='coerce').round(1)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring all soundfiles to the desired length of 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_audio = []\n",
    "target_num_samples = sr*target_seconds\n",
    "\n",
    "for i in range(len(audio_data)):\n",
    "    signal = audio_data[i][0]\n",
    "    \n",
    "    # shorten if too long, right-pad if too short\n",
    "    if len(signal) > target_num_samples:\n",
    "        processed_audio.append(signal[:sr*3])\n",
    "        \n",
    "    if len(signal) < target_num_samples:\n",
    "        num_missing_samples = target_num_samples - len(signal)\n",
    "        last_dim_padding = (0, num_missing_samples)\n",
    "        processed_audio.append(np.pad(signal, last_dim_padding, mode='constant'))\n",
    "        \n",
    "processed_audio = np.array(processed_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_scale(mfcc):\n",
    "    scaler = StandardScaler()\n",
    "    mfcc = scaler.fit_transform(np.array(mfcc))\n",
    "    return mfcc\n",
    "\n",
    "def calc_mfcc(signal):\n",
    "    return lr.feature.mfcc(y=signal, n_mfcc=n_mfcc, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_features = list()\n",
    "\n",
    "for i in tqdm(range(len(processed_audio))):\n",
    "    mfcc_features.append(mfcc_scale(calc_mfcc(processed_audio[i])))\n",
    "    \n",
    "mfcc_features = np.array(mfcc_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('mfcc_features.pickle', 'wb') as f:\n",
    "    pickle.dump(mfcc_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "# with open('norm_mfcc_features.pickle', 'rb') as f:\n",
    "#     mfcc_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(processed_audio.shape)\n",
    "print(mfcc_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and plot a single sound file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_nr = 8100\n",
    "plt.figure(figsize=(12,2))\n",
    "plt.plot(processed_audio[test_nr])\n",
    "plt.title(classID[test_nr])\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.imshow(mfcc_features[test_nr], vmin=0, vmax=1)\n",
    "plt.title(classID[test_nr])\n",
    "plt.show()\n",
    "print(fname[8100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the labels<br>\n",
    "'cel' -> '0',<br>\n",
    "'cla' -> '1' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoded = label_encoder.fit_transform(classID)\n",
    "label_encoded = label_encoded[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(label_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mfcc_features\n",
    "y = one_hot_encoded\n",
    "X = (X-X.min())/(X.max()-X.min())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "\n",
    "num_epochs = 100\n",
    "# num_steps = 1000\n",
    "activation = 'relu'\n",
    "last_act = 'Softmax'\n",
    "kernel_init = 'he_normal'\n",
    "dense_init = keras.initializers.HeNormal()\n",
    "regularizer = l2(0.01)\n",
    "padding = 'same'\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "metrics = 'acc'\n",
    "dropout_prob = 0.3\n",
    "filter_dim = (3, 3)\n",
    "\n",
    "# Early stopping parameters\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, filter_dim, activation=activation, strides=(1, 1), padding=padding, input_shape=input_shape, kernel_initializer=kernel_init))\n",
    "# model.add(MaxPool2D((2, 2), padding=padding))\n",
    "\n",
    "model.add(Conv2D(32, filter_dim, activation=activation, strides=(1, 1), padding=padding, kernel_initializer=kernel_init))\n",
    "# model.add(MaxPool2D((2, 2), padding=padding))\n",
    "\n",
    "model.add(Conv2D(64, filter_dim, activation=activation, strides=(1, 1), padding=padding, kernel_initializer=kernel_init))\n",
    "# model.add(MaxPool2D((2, 2), padding=padding))\n",
    "\n",
    "model.add(Conv2D(128, filter_dim, activation=activation, strides=(1, 1), padding=padding, kernel_initializer=kernel_init))\n",
    "model.add(MaxPool2D((2, 2), padding=padding))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=activation, kernel_initializer=dense_init, kernel_regularizer=regularizer))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024, activation=activation, kernel_initializer=dense_init, kernel_regularizer=regularizer))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation=activation, kernel_initializer=dense_init, kernel_regularizer=regularizer))\n",
    "model.add(Dense(58, activation=last_act))\n",
    "\n",
    "model.compile(loss=loss, \n",
    "     optimizer=optimizer,\n",
    "     metrics=[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping(monitor='val_loss', patience=7),\n",
    "#             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    # steps_per_epoch=num_steps,\n",
    "                    initial_epoch=0,\n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=True,\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Loss Value')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "print('loss', history.history['loss'][-1])\n",
    "print('val_loss:', history.history['val_loss'][-1])\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "print('acc:', history.history['acc'][-1])\n",
    "print('val_acc:', history.history['val_acc'][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)\n",
    "y_test = one_hot_encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm, annot=True, xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, fmt='d', cmap=plt.cm.Blues, cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba8f507fe1729c8af702a6bb6fdd2c717c7cbcb22ce2643bb02b0a4e2b11c10e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
